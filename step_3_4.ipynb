{"cells":[{"cell_type":"markdown","metadata":{"id":"E2A7HpVLr5m8"},"source":["# Storage"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"an_lT5ML9a6e"},"outputs":[],"source":["## the path to the `mldl2023` folder in your drive\n","rootMldl = '<your_drive>/mldl2023'"]},{"cell_type":"markdown","metadata":{"id":"sK-ObUBEDGAY"},"source":["# Initialization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d8pM1W1jdk05"},"outputs":[],"source":["# packages 1\n","import shutil\n","import os\n","import torch\n","\n","if not torch.cuda.is_available():\n","    raise RuntimeError('The model cannot operate without CUDA!')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9eDfj3rvdnHR"},"outputs":[],"source":["# getting the notebook's name\n","from requests import get\n","from socket import gethostname, gethostbyname\n","notebookName = get(f'http://{gethostbyname(gethostname())}:9000/api/sessions').json()[0]['name']"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26115,"status":"ok","timestamp":1686222218989,"user":{"displayName":"Homayoun Afshari","userId":"15693660695795650579"},"user_tz":-120},"id":"ykMMV6_id3Jh","outputId":"98f82d8a-8c9e-4054-e00c-9cc84a863015"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# mounting the drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bm4cdaANd-7a"},"outputs":[],"source":["# changing the root\n","os.chdir(rootMldl)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"47uuDoqfBx1q"},"outputs":[],"source":["# packages 2\n","import random\n","import string\n","from typing import Any\n","from typing import List\n","import numpy as np\n","from PIL import Image\n","from torch import from_numpy\n","from torchvision.datasets import VisionDataset\n","import datasets.ss_transforms as tr\n","from utils.stream_metrics import StreamSegMetrics\n","import torchvision.transforms as T\n","from torch.utils.data import Dataset, DataLoader\n","from models import deeplabv3, mobilenetv2\n","import torch.nn as nn\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","import torch, os, copy\n","import tqdm.notebook as tqdm\n","import gc\n","from utils.utils import HardNegativeMining, MeanReduction\n","import math\n","import json\n","import csv\n","from pprint import pprint\n","from torch import from_numpy\n","import datetime\n","import time"]},{"cell_type":"markdown","metadata":{"id":"YLz_SIPOVwfA"},"source":["# Memory Management"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6163,"status":"ok","timestamp":1686222289548,"user":{"displayName":"Homayoun Afshari","userId":"15693660695795650579"},"user_tz":-120},"id":"t0nrzYBUeHky","outputId":"ff56df29-a223-4b4e-97cd-fd4c706b81af"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting gputil\n","  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: gputil\n","  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7393 sha256=e9bd96bd55d458dd551dd33e1ca15b34fb05e816eb3c745c304a9e89e6f14d14\n","  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n","Successfully built gputil\n","Installing collected packages: gputil\n","Successfully installed gputil-1.4.0\n"]}],"source":["# packages\n","!pip install gputil\n","import prettytable\n","import psutil\n","import GPUtil"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hkT5SH-TpS34"},"outputs":[],"source":["# garbage collector\n","def clearCache():\n","    gc.collect()\n","    torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7CpcblaIUtxQ"},"outputs":[],"source":["# memory scanner\n","def printMemoryUsage(title='Memory status'):\n","    diskStatus = shutil.disk_usage('/content/')\n","    table = prettytable.PrettyTable(['type', 'available (MB)', 'used (MB)', 'free (MB)'])\n","    for field in table.field_names:\n","        table.align[field] = 'l'\n","    table.add_row([\n","        'disk',\n","        round((diskStatus[1]+diskStatus[2])/(1024*1024), 1),\n","        round((diskStatus[1])/(1024*1024), 1),\n","        round((diskStatus[2])/(1024*1024), 1)\n","    ])\n","    table.add_row([\n","        'ram',\n","        round((psutil.virtual_memory().available+psutil.virtual_memory().used)/(1024*1024), 1),\n","        round(psutil.virtual_memory().used/(1024*1024), 1),\n","        round(psutil.virtual_memory().available/(1024*1024), 1)\n","    ])\n","    for i, gpu in enumerate(GPUtil.getGPUs()):\n","        table.add_row([\n","            f'gpu-{i} ram',\n","            round(gpu.memoryUsed+gpu.memoryFree, 1),\n","            round(gpu.memoryUsed, 1),\n","            round(gpu.memoryFree, 1)\n","        ])\n","    print(title+':')\n","    print(table)\n","    print('')"]},{"cell_type":"markdown","metadata":{"id":"jcF7kIStWEaK"},"source":["# Dataset Classes"]},{"cell_type":"code","source":["class GTAVDataset(VisionDataset):\n","\n","    @staticmethod\n","    def get_mapping():\n","        classes = {\n","            1: 13, # ego_vehicle : vehicle\n","            7: 0, # road\n","            8: 1, # sidewalk\n","            11: 2, # building\n","            12: 3, # wall\n","            13: 4, # fence\n","            17: 5, # pole\n","            18: 5, # poleGroup: pole\n","            19: 6, # traffic light\n","            20: 7, # traffic sign\n","            21: 8, # vegetation\n","            22: 9, # terrain\n","            23: 10, # sky\n","            24: 11, # person\n","            25: 12, # rider\n","            26: 13, # car : vehicle\n","            27: 13, # truck : vehicle\n","            28: 13, # bus : vehicle\n","            32: 14, # motorcycle\n","            33: 15, # bicycle\n","        }\n","        mapping = np.zeros((256,), dtype=np.int64) + 255\n","        for i in classes:\n","            mapping[i] = classes[i]\n","        return lambda x: from_numpy(mapping[x])\n","\n","    def __init__(self, root, fileNames, transform=None):\n","        super().__init__(root=root, transform=transform, target_transform=GTAVDataset.get_mapping())\n","        self.fileNames = fileNames\n","\n","    def __getitem__(self, index):\n","        image = Image.open(self.root+'/images/'+self.fileNames[index]).convert('RGB').resize((1920, 1080), Image.BILINEAR)\n","        label = Image.open(self.root+'/labels/'+self.fileNames[index]).resize((1920, 1080), Image.BILINEAR)\n","        if self.transform is not None:\n","            image, label = self.transform(image, label)\n","        label = self.target_transform(label)\n","        return image, label\n","\n","    def __len__(self):\n","        return len(self.fileNames)"],"metadata":{"id":"iIZGRCiWsNca"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hXIDEx0DaudJ"},"outputs":[],"source":["class IDDADataset(VisionDataset):\n","\n","    @staticmethod\n","    def get_mapping():\n","        classes = [255, 2, 4, 255, 11, 5, 0, 0, 1, 8, 13, 3, 7, 6, 255, 255, 15, 14, 12, 9, 10]\n","        mapping = 255*np.ones(256, dtype=np.int64)\n","        mapping[range(len(classes))] = classes\n","        return lambda x: from_numpy(mapping[x])\n","\n","    def __init__(self, root, fileNames, transform=None):\n","        super().__init__(root=root, transform=transform, target_transform=IDDADataset.get_mapping())\n","        self.fileNames = fileNames\n","\n","    def __getitem__(self, index):\n","        image = Image.open(self.root+'/images/'+self.fileNames[index]+'.jpg').convert('RGB')\n","        label = Image.open(self.root+'/labels/'+self.fileNames[index]+'.png').convert('L')\n","        if self.transform is not None:\n","            image, label = self.transform(image, label)\n","        label = self.target_transform(label)\n","        return image, label\n","\n","    def __len__(self):\n","        return len(self.fileNames)"]},{"cell_type":"markdown","metadata":{"id":"JIgFSnfk2J-3"},"source":["# Server class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JZd0_ZUdB0Zd"},"outputs":[],"source":["class Server:\n","\n","    def __init__(self,\n","                 device, model,\n","                 datasetTrain, datasetTestIdda, datasetTestSame, datasetTestDiff,\n","                 batchSizeTrain, batchSizeTest,\n","                 metricClass, num_epochs,\n","                 scheduler_dict, optimizer_dict,\n","                 notebookName, pathStorage, lastEpoch, bestEpochIdda, bestMiouIdda, bestEpochSame, bestMiouSame, bestEpochDiff, bestMiouDiff):\n","\n","        self.device = device\n","        self.model = model\n","\n","        self.dataLoaderTrain = DataLoader(datasetTrain, batch_size=batchSizeTrain, shuffle=True, drop_last=True)\n","        self.dataLoaderTestIdda = DataLoader(datasetTestIdda, batch_size=batchSizeTest, shuffle=False, drop_last=False)\n","        self.dataLoaderTestSame = DataLoader(datasetTestSame, batch_size=batchSizeTest, shuffle=False, drop_last=False)\n","        self.dataLoaderTestDiff = DataLoader(datasetTestDiff, batch_size=batchSizeTest, shuffle=False, drop_last=False)\n","\n","        self.metricClass = metricClass\n","        self.num_epochs = num_epochs\n","\n","        # manually programmed cosine annealing scheduler\n","        self.scheduler = lambda epoch: scheduler_dict['lr_min'] + 0.5*(scheduler_dict['lr_initial']-scheduler_dict['lr_min'])*(1+math.cos(math.pi*epoch/scheduler_dict['T_max']))\n","        self.optimizer_dict = optimizer_dict\n","\n","        # STORAGE\n","        self.notebookName = notebookName                                        # STORAGE\n","        self.pathStorage = pathStorage                                          # STORAGE\n","        self.initialEpoch = lastEpoch + 1                                       # STORAGE\n","        self.bestEpochIdda = bestEpochIdda                                      # STORAGE\n","        self.bestMiouIdda = bestMiouIdda                                        # STORAGE\n","        self.bestEpochSame = bestEpochSame                                      # STORAGE\n","        self.bestMiouSame = bestMiouSame                                        # STORAGE\n","        self.bestEpochDiff = bestEpochDiff                                      # STORAGE\n","        self.bestMiouDiff = bestMiouDiff                                        # STORAGE\n","        # STORAGE\n","\n","        self.lr = self.scheduler(self.initialEpoch)\n","\n","    def step(self):\n","        self.epoch += 1\n","        self.lr = self.scheduler(self.epoch)\n","\n","    def select_clients(self):\n","        num_clients = min(self.max_num_clients_per_epoch, len(self.clients))\n","        return random.sample(self.clients, num_clients)\n","\n","    def train(self):\n","        self.epoch = self.initialEpoch\n","        for epoch in range(self.initialEpoch, self.num_epochs):\n","            print(f'--------------------- epoch {epoch:03d} out of {self.num_epochs:03d} ---------------------')\n","\n","            start = time.perf_counter()\n","            lossTrain, miouTrain = self.train_epoch()\n","            durationTrain = int(time.perf_counter() - start)\n","            print(f'-- loss (training): {lossTrain:.5f} -- miou (training): {100*miouTrain:.3f}% -- duration (training): {durationTrain}s')\n","\n","            start = time.perf_counter()\n","            miouTestIdda = self.test(self.dataLoaderTestIdda)\n","            durationTestIdda = int(time.perf_counter() - start)\n","            print(f'-- miou (test - idda): {100*miouTestIdda:.3f}% -- duration (test - idda): {durationTestIdda}s')\n","\n","            start = time.perf_counter()\n","            miouTestSame = self.test(self.dataLoaderTestSame)\n","            durationTestSame = int(time.perf_counter() - start)\n","            print(f'-- miou (test - same): {100*miouTestSame:.3f}% -- duration (test - same): {durationTestSame}s')\n","\n","            start = time.perf_counter()\n","            miouTestDiff = self.test(self.dataLoaderTestDiff)\n","            durationTestDiff = int(time.perf_counter() - start)\n","            print(f'-- miou (test - diff): {100*miouTestDiff:.3f}% -- duration (test - diff): {durationTestDiff}s')\n","\n","            ## STORAGE\n","            print('-- storing data')\n","            with open(self.pathStorage+'/'+'metrics.csv', 'a') as file:\n","                csv_writer = csv.writer(file)\n","                csv_writer.writerow([epoch, lossTrain, miouTrain, miouTestIdda, miouTestSame, miouTestDiff, durationTrain, durationTestIdda, durationTestSame, durationTestDiff])\n","                file.close()\n","\n","            torch.save(self.model.state_dict(), self.pathStorage+f'/model-main.pth')\n","            models = ['main']\n","            if miouIdda > self.bestMiouIdda:\n","                self.bestEpochIdda = epoch\n","                self.bestMiouIdda = miouIdda\n","                torch.save(self.model.state_dict(), self.pathStorage+f'/model-bestIdda.pth')\n","                models.append('bestIdda')\n","            if miouSame > self.bestMiouSame:\n","                self.bestEpochSame = epoch\n","                self.bestMiouSame = miouSame\n","                torch.save(self.model.state_dict(), self.pathStorage+f'/model-bestSame.pth')\n","                models.append('bestSame')\n","            if miouDiff > self.bestMiouDiff:\n","                self.bestEpochDiff = epoch\n","                self.bestMiouDiff = miouDiff\n","                torch.save(self.model.state_dict(), self.pathStorage+f'/model-bestDiff.pth')\n","                models.append('bestDiff')\n","\n","            with open(self.pathStorage+'/'+'log.txt', 'a') as file:\n","                file.write(f'-- models were overwritten on '+datetime.datetime.now().strftime('%Y-%m-%d at %H:%M:%S')+f' by {self.notebookName}\\n')\n","                file.write(f'   models: [{\", \".join(models)}]\\n')\n","                file.write(f'   last successful epoch: {epoch}\\n')\n","                file.write(f'   best record of idda: [{self.bestEpochIdda}, {self.bestMiouIdda}]\\n')\n","                file.write(f'   best record of same: [{self.bestEpochSame}, {self.bestMiouSame}]\\n')\n","                file.write(f'   best record of diff: [{self.bestEpochDiff}, {self.bestMiouDiff}]\\n')\n","                file.close()\n","            ## STORAGE\n","\n","    def train_epoch(self):\n","\n","        # training the model\n","        optimizer = torch.optim.SGD(self.model.parameters(), lr=self.lr, **self.optimizer_dict)\n","        criterion = nn.CrossEntropyLoss(ignore_index=255)\n","        clearCache()\n","        self.model.train()\n","\n","        lossCum = 0.0\n","        metric = self.metricClass(n_classes=21, name='miou')\n","        pbar = tqdm.tqdm(\n","            total = len(self.dataLoaderTrain),\n","            desc = 'training'\n","        )\n","        for batch, (images, labels) in enumerate(self.dataLoaderTrain):\n","            pbar.set_postfix({\n","                'batch': f'{batch+1}/{len(self.dataLoaderTrain)}'\n","            })\n","            images = images.to(device)\n","            labels = labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = self.model(images)['out']\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            lossCum = (batch*lossCum + loss.item())/(batch + 1)\n","            _, prediction = outputs.max(dim=1)\n","            metric.update(labels.cpu().numpy(), prediction.cpu().numpy())\n","            pbar.update(1)\n","\n","        # closing the progress bar\n","        pbar.close()\n","\n","        # stepping the scheduler\n","        self.step()\n","\n","        # returning the results\n","        miouCum = metric.get_results()['Mean IoU']\n","        return lossCum, miouCum\n","\n","    def test(self, dataLoader):\n","        clearCache()\n","        metric = self.metricClass(n_classes=21, name='miou')\n","        with torch.no_grad():\n","            self.model.eval()\n","            pbar = tqdm.tqdm(total=len(dataLoader), desc='testing')\n","            for batch, (images, labels) in enumerate(dataLoader):\n","                pbar.set_postfix({\n","                    'batch': f'{batch+1}/{len(dataLoader)}'\n","                })\n","                images = images.to(self.device)\n","                labels = labels.to(self.device)\n","                outputs = self.model(images)['out']\n","                _, prediction = outputs.max(dim=1)\n","                metric.update(labels.cpu().numpy(), prediction.cpu().numpy())\n","                pbar.update(1)\n","        pbar.close()\n","        miouCum = metric.get_results()['Mean IoU']\n","        return miouCum"]},{"cell_type":"markdown","source":["# FDA Class"],"metadata":{"id":"Kg8Q6gu9ZC41"}},{"cell_type":"code","source":["\"\"\"\n","this class can be used just like a pytorch transformer,\n","just initialize it with the root to the styles and the size of the middle\n","square wanted and put this transformer in the \"tr.Compose()\"\n","\"\"\"\n","\n","\n","class FDA(object):\n","\n","    def __init__(self, root, size=2):\n","        self.size = size\n","        self.root = root\n","        self.clientstyles = dict()\n","        for fileName in os.listdir(root):\n","            base, extension = os.path.splitext(fileName)\n","            if extension == '.json':\n","                with open(root+'/'+fileName) as f:\n","                    clientstyle = json.load(f)\n","                    style = np.array(clientstyle[base])\n","                    rows, cols, channels = style.shape\n","                    row_start = rows // 2 - int(self.size/2)\n","                    row_end = rows // 2 + int(self.size/2)\n","                    col_start = cols // 2 - int(self.size/2)\n","                    col_end = cols // 2 + int(self.size/2)\n","\n","                    # save only the part that will be used of the clients' styles\n","                    style = style[row_start:row_end, col_start:col_end, :]\n","                    self.clientstyles[base] = style\n","                    f.close\n","\n","    def __call__(self, img, lbl=None):\n","        #convert the image to numpy\n","        imgnp = np.array(img)\n","\n","        #get a random client\n","        name =  random.choice(list(self.clientstyles.keys()))\n","\n","        # convert the list of lists into numpy array\n","        style = self.clientstyles[name]\n","\n","        #fft of the gta image, on the height and width\n","        imgfft = np.fft.fftshift(np.fft.fft2(imgnp, axes=(0, 1)), axes=(0, 1))\n","\n","        # get the shape of the image\n","        rows, cols, channels = imgnp.shape\n","\n","        # define the coordinates of the middle part\n","        row_start = rows // 2 - int(self.size/2)\n","        row_end = rows // 2 + int(self.size/2)\n","        col_start = cols // 2 - int(self.size/2)\n","        col_end = cols // 2 + int(self.size/2)\n","\n","        # get amplitude and phase of the fft\n","        imgfftamplitude = np.abs(imgfft)\n","        phase = np.angle(imgfft)\n","\n","        #exchange the middle part with the client style\n","        imgfftamplitude[row_start:row_end, col_start:col_end, :] = style\n","\n","        # inverse Fourier Transform using the modified amplitude (keeping the phase intact)\n","        # different sources showed that i needed to do np.real or np.abs\n","        # i tested both, and what looked like worked better was np.abs\n","        # so i left it with np.abs\n","        mod = np.abs(np.fft.ifft2(np.fft.ifftshift(imgfftamplitude * np.exp(1j * phase), axes=(0,1)), axes=(0, 1)))\n","\n","        # clip and convert the result back to the original image type (e.g., uint8)\n","        mod = np.clip(mod, 0, 255)\n","        mod = mod.astype(np.uint8)\n","\n","        # Convert the modified image array back to PIL image\n","        mod = Image.fromarray(mod)\n","\n","        if lbl is None:\n","            return mod\n","        else:\n","            return mod, lbl"],"metadata":{"id":"GyPRLDk3d7z4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PndQNKkiEn7G"},"source":["# Different Things"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SfjsSwE2nH1_"},"outputs":[],"source":["# params class\n","class Params:\n","    def __init__(self, **args):\n","        for key, value in args.items():\n","            setattr(self, key, value)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d7Xaok_Jpp4a"},"outputs":[],"source":["# names reader\n","def getFileNames(root, containerName):\n","    fileNames = []\n","    with open(os.path.join(root, containerName), 'r') as file:\n","        for line in file.read().splitlines():\n","            fileNames.append(line)\n","    return fileNames"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t9ZfrtT9nRN-"},"outputs":[],"source":["# main function\n","def main(pathStorage, params=None, config=None):\n","    print('path: '+pathStorage)\n","\n","    # storage\n","    if os.path.exists(pathStorage):\n","        with open(pathStorage+'/log.txt') as file:\n","            lines = file.readlines()\n","            lastEpochLine = lines[-4]\n","            recordIddaLine = lines[-3]\n","            recordSameLine = lines[-2]\n","            recordDiffLine = lines[-1]\n","            lastEpoch = lastEpochLine[lastEpochLine.find(':')+2:-1]\n","            bestEpochIdda = int(recordIddaLine[recordIddaLine.find(':')+3:recordIddaLine.find(',')])\n","            bestMiouIdda = float(recordIddaLine[recordIddaLine.find(',')+2:-2])\n","            bestEpochSame = int(recordSameLine[recordSameLine.find(':')+3:recordSameLine.find(',')])\n","            bestMiouSame = float(recordSameLine[recordSameLine.find(',')+2:-2])\n","            bestEpochDiff = int(recordDiffLine[recordDiffLine.find(':')+3:recordDiffLine.find(',')])\n","            bestMiouDiff = float(recordDiffLine[recordDiffLine.find(',')+2:-2])\n","            file.close()\n","\n","        with open(pathStorage+'/params.json') as file:\n","            params = Params(**json.load(file))\n","            file.close()\n","\n","        clearCache()\n","        model = deeplabv3.deeplabv3_mobilenetv2().to(params.device)\n","        model.load_state_dict(torch.load(pathStorage+'/'+f'model-main.pth'))\n","\n","        with open(pathStorage+'/log.txt', 'a') as file:\n","            file.write(f'-- models were loaded on '+datetime.datetime.now().strftime('%Y-%m-%d at %H:%M:%S')+f' by {notebookName}\\n')\n","            file.write(f'   models: [main]\\n')\n","            file.write(f'   last successful epoch: {lastEpoch}\\n')\n","            file.write(recordIddaLine)\n","            file.write(recordSameLine)\n","            file.write(recordDiffLine)\n","            file.close()\n","        lastEpoch = -1 if lastEpoch == 'n/a' else int(lastEpoch)\n","        if (lastEpoch == params.num_epochs - 1):\n","            print('-- this config is finished!')\n","            return\n","\n","    else:\n","        for key, value in config.items():\n","            if hasattr(params, key):\n","                setattr(params, key, value)\n","            else:\n","                raise RuntimeError(f'Make sure each key of `config` is already an attribute of `params`! The key `{key}` does not exist!')\n","\n","        os.makedirs(pathStorage, exist_ok=True)\n","\n","        with open(pathStorage+'/params.json', 'w') as file:\n","            json.dump(params.__dict__, file, indent=4)\n","            file.close()\n","\n","        with open(pathStorage+'/config.json', 'w') as file:\n","            json.dump(dict(config), file, indent=4)\n","            file.close()\n","\n","        with open(pathStorage+'/metrics.csv', 'w', newline='') as file:\n","            csv_writer = csv.writer(file)\n","            csv_writer.writerow(['epoch', 'lossTrain', 'miouTrain', 'miouTestIdda', 'miouTestSame', 'miouTestDiff', 'durationTrain', 'durationTestIdda', 'durationTestSame', 'durationTestDiff'])\n","            file.close()\n","\n","        clearCache()\n","        model = deeplabv3.deeplabv3_mobilenetv2().to(params.device)\n","\n","        torch.save(model.state_dict(), pathStorage+'/model-main.pth')\n","        torch.save(model.state_dict(), pathStorage+'/model-bestIdda.pth')\n","        torch.save(model.state_dict(), pathStorage+'/model-bestSame.pth')\n","        torch.save(model.state_dict(), pathStorage+'/model-bestDiff.pth')\n","        with open(pathStorage+'/log.txt', 'w') as file:\n","            file.write('-- models were created on '+datetime.datetime.now().strftime('%Y-%m-%d at %H:%M:%S')+f' by {notebookName}\\n')\n","            file.write('   models: [main, bestIdda, bestSame, bestDiff]\\n')\n","            file.write('   last successful epoch: n/a\\n')\n","            file.write('   best record of idda: [0, 0.0]\\n')\n","            file.write('   best record of same: [0, 0.0]\\n')\n","            file.write('   best record of diff: [0, 0.0]\\n')\n","            file.close()\n","        lastEpoch = -1\n","        bestEpochIdda = 0\n","        bestMiouIdda = 0.0\n","        bestEpochSame = 0\n","        bestMiouSame = 0.0\n","        bestEpochDiff = 0\n","        bestMiouDiff = 0.0\n","\n","    # transformers\n","    transformsTrain = tr.Compose([\n","        FDA(root=params.rootIdda+'/styles', size=params.transformer_fdaSize),\n","        tr.RandomResizedCrop(size=tuple(params.transformer_imageSize),scale=params.transformer_scale),\n","        tr.ColorJitter(*params.transformer_jitter),\n","        tr.RandomHorizontalFlip(),\n","        tr.ToTensor(),\n","        tr.Normalize(tuple(params.transformer_means), tuple(params.transformer_stds))\n","    ])\n","    transformsTest = tr.Compose([\n","        tr.ToTensor(),\n","        tr.Normalize(tuple(params.transformer_means), tuple(params.transformer_stds))\n","    ])\n","\n","    # server\n","    server = Server(\n","        device = params.device,\n","        model = model,\n","        datasetTrain = GTAVDataset(\n","            root = params.rootGtav,\n","            fileNames = getFileNames(params.rootGtav, 'train.txt'),\n","            transform = transformsTrain\n","        ),\n","        datasetTestIdda = IDDADataset(\n","            root = params.rootIdda,\n","            fileNames = getFileNames(params.rootIdda, 'train.txt'),\n","            transform = transformsTest\n","        ),\n","        datasetTestSame = IDDADataset(\n","            root = params.rootIdda,\n","            fileNames = getFileNames(params.rootIdda, 'test_same_dom.txt'),\n","            transform = transformsTest\n","        ),\n","        datasetTestDiff = IDDADataset(\n","            root = params.rootIdda,\n","            fileNames = getFileNames(params.rootIdda, 'test_diff_dom.txt'),\n","            transform = transformsTest\n","        ),\n","        batchSizeTrain = params.batchSizeTrain,\n","        batchSizeTest = params.batchSizeTest,\n","        metricClass = StreamSegMetrics,\n","        num_epochs = params.num_epochs,\n","        scheduler_dict = {\n","            'lr_initial': params.scheduler_lr_initial,\n","            'lr_min':  params.scheduler_lr_min,\n","            'T_max': params.scheduler_T_max\n","        },\n","        optimizer_dict = {\n","            'momentum': params.optimizer_momentum,\n","            'weight_decay': params.optimizer_weight_decay\n","        },\n","        notebookName = notebookName,                                            # STORAGE\n","        pathStorage = pathStorage,                                              # STORAGE\n","        lastEpoch = lastEpoch,                                                  # STORAGE\n","        bestEpochIdda = bestEpochIdda,                                          # STORAGE\n","        bestMiouIdda = bestMiouIdda,                                            # STORAGE\n","        bestEpochSame = bestEpochSame,                                          # STORAGE\n","        bestMiouSame = bestMiouSame,                                            # STORAGE\n","        bestEpochDiff = bestEpochDiff,                                          # STORAGE\n","        bestMiouDiff = bestMiouDiff                                             # STORAGE\n","    )\n","\n","    # train federated learning\n","    server.train()"]},{"cell_type":"markdown","metadata":{"id":"-9pfYAKiHVC_"},"source":["# Server Driver"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7nXCNfH8n78G"},"outputs":[],"source":["# params\n","## the intitial parameters (default config)\n","## if there's a config value for a parameter, it'll be overwritten\n","params = Params(\n","    device = 'cuda:0',\n","    rootGtav = '/content/data/gtav',\n","    rootIdda = '/content/data/idda',\n","    rootStorage = rootMldl+'/storage/step3/part4',\n","    batchSizeTrain = 3,\n","    batchSizeTest = 3,\n","    transformer_fdaSize = 2,\n","    transformer_imageSize = [1080, 1920],\n","    transformer_scale = [0.25, 1],\n","    transformer_jitter = [0.4, 0.4, 0.5, 0.1],\n","    transformer_means = [0.320888, 0.292300, 0.288562],\n","    transformer_stds  = [0.250606, 0.248234, 0.253670],\n","    num_epochs = 100,                                                           # server\n","    scheduler_lr_initial = 0.1,                                                 # server (scheduler parameter)\n","    scheduler_lr_min = 0,                                                       # server (scheduler parameter)\n","    scheduler_T_max = 300,                                                      # server (scheduler parameter)\n","    optimizer_momentum = 0.65,                                                  # client (optimzer parameter)\n","    optimizer_weight_decay = 0.0005                                             # client (optimzer parameter)\n",")"]},{"cell_type":"code","source":["# copies\n","print('Copying GTAV dataset ...')\n","shutil.copytree(rootMldl+'/data/GTA5', params.rootGtav, dirs_exist_ok=True)\n","print('Copying IDDA data ...')\n","shutil.copytree(rootMldl+'/data/idda', params.rootIdda, dirs_exist_ok=True)\n","print('Copying styles ...')\n","shutil.copytree(rootMldl+'/data/idda/styles', params.rootIdda+'/styles', dirs_exist_ok=True)"],"metadata":{"id":"W9WSGqjsqUpL"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tOmFXj0kpD-6"},"outputs":[],"source":["# configs\n","## make sure each key of `config` is already an attribute of `params`\n","config = {\n","    'transformer_fdaSize': 4,\n","}\n","\n","# storage\n","folderName = []\n","for key, value in config.items():\n","    args = key.split('_')\n","    folderName.append((''.join([arg[:2].capitalize() for arg in args]))+'='+str(value))\n","folderName = ','.join(folderName)\n","\n","# driver\n","pathStorage = params.rootStorage+'/'+folderName\n","if os.path.exists(params.rootStorage) and (folderName in os.listdir(params.rootStorage)):\n","    main(pathStorage)\n","else:\n","    main(\n","        params = params,\n","        config = config,\n","        pathStorage = params.rootStorage+'/'+folderName\n","    )"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["sK-ObUBEDGAY","YLz_SIPOVwfA","jcF7kIStWEaK","JIgFSnfk2J-3","Kg8Q6gu9ZC41","PndQNKkiEn7G"],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}