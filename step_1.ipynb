{"cells":[{"cell_type":"markdown","metadata":{"id":"E2A7HpVLr5m8"},"source":["# Storage"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WZUNtulY0IR5"},"outputs":[],"source":["## the path to the `mldl2023` folder in your drive\n","rootMldl = '<your_drive>/mldl2023'"]},{"cell_type":"markdown","metadata":{"id":"sK-ObUBEDGAY"},"source":["# Initialization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d8pM1W1jdk05"},"outputs":[],"source":["# packages 1\n","import shutil\n","import os\n","import torch\n","\n","if not torch.cuda.is_available():\n","    raise RuntimeError('The model cannot operate without CUDA!')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9eDfj3rvdnHR"},"outputs":[],"source":["# getting the notebook's name\n","from requests import get\n","from socket import gethostname, gethostbyname\n","notebookName = get(f'http://{gethostbyname(gethostname())}:9000/api/sessions').json()[0]['name']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ykMMV6_id3Jh"},"outputs":[],"source":["# mounting the drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bm4cdaANd-7a"},"outputs":[],"source":["# changing the root\n","os.chdir(rootMldl)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"47uuDoqfBx1q"},"outputs":[],"source":["# packages 2\n","import random\n","import string\n","from typing import Any\n","from typing import List\n","import numpy as np\n","from PIL import Image\n","from torch import from_numpy\n","from torchvision.datasets import VisionDataset\n","import datasets.ss_transforms as tr\n","from utils.stream_metrics import StreamSegMetrics\n","import torchvision.transforms as T\n","from torch.utils.data import Dataset, DataLoader\n","from models import deeplabv3, mobilenetv2\n","import torch.nn as nn\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","import torch, os, copy\n","import tqdm.notebook as tqdm\n","import gc\n","from utils.utils import HardNegativeMining, MeanReduction\n","import math\n","import json\n","import csv\n","from pprint import pprint\n","from torch import from_numpy\n","import datetime\n","import time"]},{"cell_type":"markdown","metadata":{"id":"YLz_SIPOVwfA"},"source":["# Memory Management"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t0nrzYBUeHky"},"outputs":[],"source":["# packages\n","!pip install gputil\n","import prettytable\n","import psutil\n","import GPUtil"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hkT5SH-TpS34"},"outputs":[],"source":["# garbage collector\n","def clearCache():\n","    gc.collect()\n","    torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7CpcblaIUtxQ"},"outputs":[],"source":["# memory scanner\n","def printMemoryUsage(title='Memory status'):\n","    diskStatus = shutil.disk_usage('/content/')\n","    table = prettytable.PrettyTable(['type', 'available (MB)', 'used (MB)', 'free (MB)'])\n","    for field in table.field_names:\n","        table.align[field] = 'l'\n","    table.add_row([\n","        'disk',\n","        round((diskStatus[1]+diskStatus[2])/(1024*1024), 1),\n","        round((diskStatus[1])/(1024*1024), 1),\n","        round((diskStatus[2])/(1024*1024), 1)\n","    ])\n","    table.add_row([\n","        'ram',\n","        round((psutil.virtual_memory().available+psutil.virtual_memory().used)/(1024*1024), 1),\n","        round(psutil.virtual_memory().used/(1024*1024), 1),\n","        round(psutil.virtual_memory().available/(1024*1024), 1)\n","    ])\n","    for i, gpu in enumerate(GPUtil.getGPUs()):\n","        table.add_row([\n","            f'gpu-{i} ram',\n","            round(gpu.memoryUsed+gpu.memoryFree, 1),\n","            round(gpu.memoryUsed, 1),\n","            round(gpu.memoryFree, 1)\n","        ])\n","    print(title+':')\n","    print(table)\n","    print('')"]},{"cell_type":"markdown","metadata":{"id":"jcF7kIStWEaK"},"source":["# Dataset Class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hXIDEx0DaudJ"},"outputs":[],"source":["class IDDADataset(VisionDataset):\n","\n","    @staticmethod\n","    def get_mapping():\n","        classes = [255, 2, 4, 255, 11, 5, 0, 0, 1, 8, 13, 3, 7, 6, 255, 255, 15, 14, 12, 9, 10]\n","        mapping = 255*np.ones(256, dtype=np.int64)\n","        mapping[range(len(classes))] = classes\n","        return lambda x: from_numpy(mapping[x])\n","\n","    def __init__(self, root, fileNames, transform=None):\n","        super().__init__(root=root, transform=transform, target_transform=IDDADataset.get_mapping())\n","        self.fileNames = fileNames\n","\n","    def __getitem__(self, index):\n","        image = Image.open(self.root+'/images/'+self.fileNames[index]+'.jpg').convert('RGB')\n","        label = Image.open(self.root+'/labels/'+self.fileNames[index]+'.png').convert('L')\n","        if self.transform is not None:\n","            image, label = self.transform(image, label)\n","        label = self.target_transform(label)\n","        return image, label\n","\n","    def __len__(self):\n","        return len(self.fileNames)"]},{"cell_type":"markdown","metadata":{"id":"JIgFSnfk2J-3"},"source":["# Server class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JZd0_ZUdB0Zd"},"outputs":[],"source":["class Server:\n","\n","    def __init__(self,\n","                 device, model,\n","                 datasetTrain, datasetTestSame, datasetTestDiff,\n","                 batchSizeTrain, batchSizeTest,\n","                 metricClass, num_epochs,\n","                 scheduler_dict, optimizer_dict,\n","                 notebookName, pathStorage, lastEpoch, bestEpochSame, bestMiouSame, bestEpochDiff, bestMiouDiff):\n","\n","        self.device = device\n","        self.model = model\n","\n","        self.dataLoaderTrain = DataLoader(datasetTrain, batch_size=batchSizeTrain, shuffle=True, drop_last=True)\n","        self.dataLoaderTestSame = DataLoader(datasetTestSame, batch_size=batchSizeTest, shuffle=False, drop_last=False)\n","        self.dataLoaderTestDiff = DataLoader(datasetTestDiff, batch_size=batchSizeTest, shuffle=False, drop_last=False)\n","\n","        self.metricClass = metricClass\n","        self.num_epochs = num_epochs\n","\n","        # manually programmed cosine annealing scheduler\n","        self.scheduler = lambda epoch: scheduler_dict['lr_min'] + 0.5*(scheduler_dict['lr_initial']-scheduler_dict['lr_min'])*(1+math.cos(math.pi*epoch/scheduler_dict['T_max']))\n","        self.optimizer_dict = optimizer_dict\n","\n","        # STORAGE\n","        self.notebookName = notebookName                                        # STORAGE\n","        self.pathStorage = pathStorage                                          # STORAGE\n","        self.initialEpoch = lastEpoch + 1                                       # STORAGE\n","        self.bestEpochSame = bestEpochSame                                      # STORAGE\n","        self.bestMiouSame = bestMiouSame                                        # STORAGE\n","        self.bestEpochDiff = bestEpochDiff                                      # STORAGE\n","        self.bestMiouDiff = bestMiouDiff                                        # STORAGE\n","        # STORAGE\n","\n","        self.lr = self.scheduler(self.initialEpoch)\n","\n","    def step(self):\n","        self.epoch += 1\n","        self.lr = self.scheduler(self.epoch)\n","\n","    def select_clients(self):\n","        num_clients = min(self.max_num_clients_per_epoch, len(self.clients))\n","        return random.sample(self.clients, num_clients)\n","\n","    def train(self):\n","        self.epoch = self.initialEpoch\n","        for epoch in range(self.initialEpoch, self.num_epochs):\n","            print(f'--------------------- epoch {epoch:03d} out of {self.num_epochs:03d} ---------------------')\n","\n","            start = time.perf_counter()\n","            lossTrain, miouTrain = self.train_epoch()\n","            durationTrain = int(time.perf_counter() - start)\n","            print(f'-- loss (training): {lossTrain:.5f} -- miou (training): {100*miouTrain:.3f}% -- duration (training): {durationTrain}s')\n","\n","            start = time.perf_counter()\n","            miouTestSame = self.test(self.dataLoaderTestSame)\n","            durationTestSame = int(time.perf_counter() - start)\n","            print(f'-- miou (test - same): {100*miouTestSame:.3f}% -- duration (test - same): {durationTestSame}s')\n","\n","            start = time.perf_counter()\n","            miouTestDiff = self.test(self.dataLoaderTestDiff)\n","            durationTestDiff = int(time.perf_counter() - start)\n","            print(f'-- miou (test - diff): {100*miouTestDiff:.3f}% -- duration (test - diff): {durationTestDiff}s')\n","\n","            ## STORAGE\n","            print('-- storing data')\n","            with open(self.pathStorage+'/'+'metrics.csv', 'a') as file:\n","                csv_writer = csv.writer(file)\n","                csv_writer.writerow([epoch, lossTrain, miouTrain, miouTestSame, miouTestDiff, durationTrain, durationTestSame, durationTestDiff])\n","                file.close()\n","\n","            torch.save(self.model.state_dict(), self.pathStorage+f'/model-main.pth')\n","            models = ['main']\n","            if miouTestSame > self.bestMiouSame:\n","                self.bestEpochSame = epoch\n","                self.bestMiouSame = miouTestSame\n","                torch.save(self.model.state_dict(), self.pathStorage+f'/model-bestSame.pth')\n","                models.append('bestSame')\n","            if miouTestDiff > self.bestMiouDiff:\n","                self.bestEpochDiff = epoch\n","                self.bestMiouDiff = miouTestDiff\n","                torch.save(self.model.state_dict(), self.pathStorage+f'/model-bestDiff.pth')\n","                models.append('bestDiff')\n","\n","            with open(self.pathStorage+'/'+'log.txt', 'a') as file:\n","                file.write(f'-- models were overwritten on '+datetime.datetime.now().strftime('%Y-%m-%d at %H:%M:%S')+f' by {self.notebookName}\\n')\n","                file.write(f'   models: [{\", \".join(models)}]\\n')\n","                file.write(f'   last successful epoch: {epoch}\\n')\n","                file.write(f'   best record of same: [{self.bestEpochSame}, {self.bestMiouSame}]\\n')\n","                file.write(f'   best record of diff: [{self.bestEpochDiff}, {self.bestMiouDiff}]\\n')\n","                file.close()\n","            ## STORAGE\n","\n","    def train_epoch(self):\n","\n","        # training the model\n","        optimizer = torch.optim.SGD(self.model.parameters(), lr=self.lr, **self.optimizer_dict)\n","        criterion = nn.CrossEntropyLoss(ignore_index=255)\n","        clearCache()\n","        self.model.train()\n","\n","        lossCum = 0.0\n","        metric = self.metricClass(n_classes=21, name='miou')\n","        pbar = tqdm.tqdm(\n","            total = len(self.dataLoaderTrain),\n","            desc = 'training'\n","        )\n","        for batch, (images, labels) in enumerate(self.dataLoaderTrain):\n","            pbar.set_postfix({\n","                'batch': f'{batch+1}/{len(self.dataLoaderTrain)}'\n","            })\n","            images = images.to(self.device)\n","            labels = labels.to(self.device)\n","\n","            optimizer.zero_grad()\n","            outputs = self.model(images)['out']\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            lossCum = (batch*lossCum + loss.item())/(batch + 1)\n","            _, prediction = outputs.max(dim=1)\n","            metric.update(labels.cpu().numpy(), prediction.cpu().numpy())\n","            pbar.update(1)\n","\n","        # closing the progress bar\n","        pbar.close()\n","\n","        # stepping the scheduler\n","        self.step()\n","\n","        # returning the results\n","        miouCum = metric.get_results()['Mean IoU']\n","        return lossCum, miouCum\n","\n","    def test(self, dataLoader):\n","        clearCache()\n","        metric = self.metricClass(n_classes=21, name='miou')\n","        with torch.no_grad():\n","            self.model.eval()\n","            pbar = tqdm.tqdm(total=len(dataLoader), desc='testing')\n","            for batch, (images, labels) in enumerate(dataLoader):\n","                pbar.set_postfix({\n","                    'batch': f'{batch+1}/{len(dataLoader)}'\n","                })\n","                images = images.to(self.device)\n","                labels = labels.to(self.device)\n","                outputs = self.model(images)['out']\n","                _, prediction = outputs.max(dim=1)\n","                metric.update(labels.cpu().numpy(), prediction.cpu().numpy())\n","                pbar.update(1)\n","        pbar.close()\n","        miouCum = metric.get_results()['Mean IoU']\n","        return miouCum"]},{"cell_type":"markdown","metadata":{"id":"PndQNKkiEn7G"},"source":["# Different Things"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SfjsSwE2nH1_"},"outputs":[],"source":["# params class\n","class Params:\n","    def __init__(self, **args):\n","        for key, value in args.items():\n","            setattr(self, key, value)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d7Xaok_Jpp4a"},"outputs":[],"source":["# names reader\n","def getFileNames(root, containerName):\n","    fileNames = []\n","    with open(os.path.join(root, containerName), 'r') as file:\n","        for line in file.read().splitlines():\n","            fileNames.append(line)\n","    return fileNames"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t9ZfrtT9nRN-"},"outputs":[],"source":["# main function\n","def main(pathStorage, params=None, config=None):\n","    print('path: '+pathStorage)\n","\n","    # storage (to continue unfinished experiments in case wanted)\n","    if os.path.exists(pathStorage):\n","        with open(pathStorage+'/log.txt') as file:\n","            lines = file.readlines()\n","            lastEpochLine = lines[-3]\n","            recordSameLine = lines[-2]\n","            recordDiffLine = lines[-1]\n","            lastEpoch = lastEpochLine[lastEpochLine.find(':')+2:-1]\n","            bestEpochSame = int(recordSameLine[recordSameLine.find(':')+3:recordSameLine.find(',')])\n","            bestMiouSame = float(recordSameLine[recordSameLine.find(',')+2:-2])\n","            bestEpochDiff = int(recordDiffLine[recordDiffLine.find(':')+3:recordDiffLine.find(',')])\n","            bestMiouDiff = float(recordDiffLine[recordDiffLine.find(',')+2:-2])\n","            file.close()\n","\n","        with open(pathStorage+'/params.json') as file:\n","            params = Params(**json.load(file))\n","            file.close()\n","\n","        clearCache()\n","        model = deeplabv3.deeplabv3_mobilenetv2().to(params.device)\n","        model.load_state_dict(torch.load(pathStorage+'/'+f'model-main.pth'))\n","\n","        with open(pathStorage+'/log.txt', 'a') as file:\n","            file.write(f'-- models were loaded on '+datetime.datetime.now().strftime('%Y-%m-%d at %H:%M:%S')+f' by {notebookName}\\n')\n","            file.write(f'   models: [main]\\n')\n","            file.write(f'   last successful epoch: {lastEpoch}\\n')\n","            file.write(recordSameLine)\n","            file.write(recordDiffLine)\n","            file.close()\n","        lastEpoch = -1 if lastEpoch == 'n/a' else int(lastEpoch)\n","        if (lastEpoch == params.num_epochs - 1):\n","            print('-- this config is finished!')\n","            return\n","\n","    else:  # for new experiments\n","        for key, value in config.items():\n","            if hasattr(params, key):\n","                setattr(params, key, value)\n","            else:\n","                raise RuntimeError(f'Make sure each key of `config` is already an attribute of `params`! The key `{key}` does not exist!')\n","\n","        os.makedirs(pathStorage, exist_ok=True)\n","\n","        with open(pathStorage+'/params.json', 'w') as file:\n","            json.dump(params.__dict__, file, indent=4)\n","            file.close()\n","\n","        with open(pathStorage+'/config.json', 'w') as file:\n","            json.dump(dict(config), file, indent=4)\n","            file.close()\n","\n","        with open(pathStorage+'/metrics.csv', 'w', newline='') as file:\n","            csv_writer = csv.writer(file)\n","            csv_writer.writerow(['epoch', 'lossTrain', 'miouTrain', 'miouTestSame', 'miouTestDiff', 'durationTrain', 'durationTestSame', 'durationTestDiff'])\n","            file.close()\n","\n","        clearCache()\n","        model = deeplabv3.deeplabv3_mobilenetv2().to(params.device)\n","\n","        torch.save(model.state_dict(), pathStorage+'/model-main.pth')\n","        torch.save(model.state_dict(), pathStorage+'/model-bestSame.pth')\n","        torch.save(model.state_dict(), pathStorage+'/model-bestDiff.pth')\n","        with open(pathStorage+'/log.txt', 'w') as file:\n","            file.write('-- models were created on '+datetime.datetime.now().strftime('%Y-%m-%d at %H:%M:%S')+f' by {notebookName}\\n')\n","            file.write('   models: [main, bestSame, bestDiff]\\n')\n","            file.write('   last successful epoch: n/a\\n')\n","            file.write('   best record of same: [0, 0.0]\\n')\n","            file.write('   best record of diff: [0, 0.0]\\n')\n","            file.close()\n","        lastEpoch = -1\n","        bestEpochSame = 0\n","        bestMiouSame = 0.0\n","        bestEpochDiff = 0\n","        bestMiouDiff = 0.0\n","\n","    # transformers\n","    transformsTrain = tr.Compose([\n","        tr.RandomResizedCrop(size=tuple(params.transformer_imageSize),scale=params.transformer_scale),\n","        tr.ColorJitter(*params.transformer_jitter),\n","        tr.RandomHorizontalFlip(),\n","        tr.ToTensor(),\n","        tr.Normalize(tuple(params.transformer_means), tuple(params.transformer_stds))\n","    ])\n","    transformsTest = tr.Compose([\n","        tr.ToTensor(),\n","        tr.Normalize(tuple(params.transformer_means), tuple(params.transformer_stds))\n","    ])\n","\n","    # server\n","    server = Server(\n","        device = params.device,\n","        model = model,\n","        datasetTrain = IDDADataset(\n","            root = params.rootIdda,\n","            fileNames = getFileNames(params.rootIdda, 'train.txt'),\n","            transform = transformsTest\n","        ),\n","        datasetTestSame = IDDADataset(\n","            root = params.rootIdda,\n","            fileNames = getFileNames(params.rootIdda, 'test_same_dom.txt'),\n","            transform = transformsTest\n","        ),\n","        datasetTestDiff = IDDADataset(\n","            root = params.rootIdda,\n","            fileNames = getFileNames(params.rootIdda, 'test_diff_dom.txt'),\n","            transform = transformsTest\n","        ),\n","        batchSizeTrain = params.batchSizeTrain,\n","        batchSizeTest = params.batchSizeTest,\n","        metricClass = StreamSegMetrics,\n","        num_epochs = params.num_epochs,\n","        scheduler_dict = {\n","            'lr_initial': params.scheduler_lr_initial,\n","            'lr_min':  params.scheduler_lr_min,\n","            'T_max': params.scheduler_T_max\n","        },\n","        optimizer_dict = {\n","            'momentum': params.optimizer_momentum,\n","            'weight_decay': params.optimizer_weight_decay\n","        },\n","        notebookName = notebookName,                                            # STORAGE\n","        pathStorage = pathStorage,                                              # STORAGE\n","        lastEpoch = lastEpoch,                                                  # STORAGE\n","        bestEpochSame = bestEpochSame,                                          # STORAGE\n","        bestMiouSame = bestMiouSame,                                            # STORAGE\n","        bestEpochDiff = bestEpochDiff,                                          # STORAGE\n","        bestMiouDiff = bestMiouDiff                                             # STORAGE\n","    )\n","\n","    # train federated learning\n","    server.train()"]},{"cell_type":"markdown","metadata":{"id":"-9pfYAKiHVC_"},"source":["# Server Driver"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7nXCNfH8n78G"},"outputs":[],"source":["# params\n","## the intitial parameters (default config)\n","## if there's a config value for a parameter, it'll be overwritten\n","params = Params(\n","    device = 'cuda:0',\n","    rootIdda = '/content/data/idda',\n","    rootStorage = rootMldl+'/storage/step1',\n","    batchSizeTrain = 3,\n","    batchSizeTest = 3,\n","    transformer_imageSize = [1080, 1920],\n","    transformer_scale = [0.25, 1],\n","    transformer_jitter = [0.4, 0.4, 0.5, 0.1],\n","    transformer_means = [0.320888, 0.292300, 0.288562],\n","    transformer_stds  = [0.250606, 0.248234, 0.253670],\n","    num_epochs = 40,                                                            # server\n","    scheduler_lr_initial = 0.1,                                                 # server (scheduler parameter)\n","    scheduler_lr_min = 0,                                                       # server (scheduler parameter)\n","    scheduler_T_max = 40,                                                       # server (scheduler parameter)\n","    optimizer_momentum = 0.65,                                                  # client (optimzer parameter)\n","    optimizer_weight_decay = 0.0005                                             # client (optimzer parameter)\n",")"]},{"cell_type":"code","source":["# copies\n","print('Copying IDDA data ...')\n","shutil.copytree(rootMldl+'/data/idda', params.rootIdda, dirs_exist_ok=True)"],"metadata":{"id":"W9WSGqjsqUpL"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tOmFXj0kpD-6"},"outputs":[],"source":["# configs\n","## make sure each key of `config` is already an attribute of `params`\n","config = {\n","    'scheduler_lr_initial': 0.1,\n","    'optimizer_momentum': 0.65,\n","    'optimizer_weight_decay': 0.0005\n","}\n","\n","# storage\n","folderName = []\n","for key, value in config.items():\n","    args = key.split('_')\n","    folderName.append((''.join([arg[:2].capitalize() for arg in args]))+'='+str(value))\n","folderName = ','.join(folderName)\n","\n","# driver\n","pathStorage = params.rootStorage+'/'+folderName\n","if os.path.exists(params.rootStorage) and (folderName in os.listdir(params.rootStorage)):\n","    main(pathStorage)\n","else:\n","    main(\n","        params = params,\n","        config = config,\n","        pathStorage = params.rootStorage+'/'+folderName\n","    )"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"collapsed_sections":["sK-ObUBEDGAY","YLz_SIPOVwfA","jcF7kIStWEaK","JIgFSnfk2J-3","PndQNKkiEn7G"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}